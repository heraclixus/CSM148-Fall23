{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHeN3ilmZapM"
   },
   "source": [
    "# Regularization and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMm2jZ7WN-Js"
   },
   "source": [
    "## Remember the 3 integral steps!\n",
    "\n",
    "\n",
    "1.   Model construction\n",
    "2.   Model usage\n",
    "3.   Model selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tunyMC1zOqLz"
   },
   "source": [
    "## We've talked about step 1 (Model construction)...\n",
    "\n",
    "We use our training data to find our estimates\n",
    "\n",
    "## And we've talked about step 2 (Model usage)...\n",
    "\n",
    "We use our data against test data\n",
    "\n",
    "## \"...So what about model selection?\n",
    "\n",
    "How do we know which model will be the best fit for our data? How do we prevent overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgscR3trPGWq"
   },
   "source": [
    "## Variable selection\n",
    "\n",
    "We can use stepwise variable selection to select the best predictors using stepwise variable selection & cross validation!\n",
    "\n",
    "In stepwise variable selection we iteratively find the optimal set of predictors by slowly building up how many predictors we are using.\n",
    "\n",
    "1. Start with no predictors\n",
    "2. Choose the predictor with the highest R^2 value (or other metric)\n",
    "3. Select the next predictor that increases the R^2 value until no new candidates remain that will increase the R^2 (again, or other metric we are using the evaluate our model's accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApSeyjImROVF"
   },
   "source": [
    "#Variable (forward) selection example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMH1qrk5Qrv_"
   },
   "source": [
    "Download the .csv file from this link here: https://drive.google.com/file/d/10UeKpTSuqPnTeydHmqrSzYGbvVoCX4zF/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8Kw62lTRGzf"
   },
   "source": [
    "Import your libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22163,
     "status": "ok",
     "timestamp": 1626296406437,
     "user": {
      "displayName": "Advaith Gowrishetty",
      "photoUrl": "",
      "userId": "06283302651145676231"
     },
     "user_tz": -330
    },
    "id": "TAwOWjclQhD9",
    "outputId": "51caf242-aa58-4827-ee17-9d3704a4660d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WE8aotSVjZvk"
   },
   "source": [
    "Before going forward, let's uninstall and reinstall scikit learn\n",
    "This is because colab's default sklearn is version 0.22.2, and we want 0.24.2 for this since 0.22.2 does not have sequential feature selection!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oU303k7Td_o"
   },
   "source": [
    "Load our dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hPUaPJzERQez"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('student_scores_extended.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99DMfXqqThVS"
   },
   "source": [
    "Explore our dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1626296479631,
     "user": {
      "displayName": "Advaith Gowrishetty",
      "photoUrl": "",
      "userId": "06283302651145676231"
     },
     "user_tz": -330
    },
    "id": "Z4Dg1EAwT6NH",
    "outputId": "264b6cb4-91d0-4551-8cce-797e575929c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Previous score</th>\n",
       "      <th>Prereqs taken</th>\n",
       "      <th>ID number</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>8751</td>\n",
       "      <td>2.5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>4186</td>\n",
       "      <td>5.1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1096</td>\n",
       "      <td>3.2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>5943</td>\n",
       "      <td>8.5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2723</td>\n",
       "      <td>3.5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>7472</td>\n",
       "      <td>1.5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>7122</td>\n",
       "      <td>9.2</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>7776</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>4072</td>\n",
       "      <td>8.3</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6087</td>\n",
       "      <td>2.7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Previous score  Prereqs taken  ID number  Hours  Scores\n",
       "0              33              0       8751    2.5      21\n",
       "1              45              0       4186    5.1      47\n",
       "2              28              0       1096    3.2      27\n",
       "3              80              1       5943    8.5      75\n",
       "4              50              0       2723    3.5      30\n",
       "5              18              0       7472    1.5      20\n",
       "6              95              2       7122    9.2      88\n",
       "7              75              1       7776    5.5      60\n",
       "8             100              1       4072    8.3      81\n",
       "9              10              0       6087    2.7      25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1626296483874,
     "user": {
      "displayName": "Advaith Gowrishetty",
      "photoUrl": "",
      "userId": "06283302651145676231"
     },
     "user_tz": -330
    },
    "id": "ga6f5cT_kh48",
    "outputId": "8c553c51-43f3-440e-da65-1718e206827e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Previous score  25 non-null     int64  \n",
      " 1   Prereqs taken   25 non-null     int64  \n",
      " 2   ID number       25 non-null     int64  \n",
      " 3   Hours           25 non-null     float64\n",
      " 4   Scores          25 non-null     int64  \n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 1.1 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qte-2IPKUIRw"
   },
   "source": [
    "Let's plot each attribute and see what it looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1605,
     "status": "ok",
     "timestamp": 1626296499404,
     "user": {
      "displayName": "Advaith Gowrishetty",
      "photoUrl": "",
      "userId": "06283302651145676231"
     },
     "user_tz": -330
    },
    "id": "5KQJ7Uo0UMqk",
    "outputId": "1f59357f-fe6d-4369-fad0-6f4d2a2506b7"
   },
   "outputs": [],
   "source": [
    "# Let's try using matplotlib \n",
    "# and then seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jTecwQjUjEF"
   },
   "source": [
    "**What do you notice about these plots already?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1R3f7O_gXAe"
   },
   "source": [
    "Now let's do forward selection! First, get out training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "executionInfo": {
     "elapsed": 787,
     "status": "error",
     "timestamp": 1626300024415,
     "user": {
      "displayName": "STEPHANIE SHIN",
      "photoUrl": "",
      "userId": "10583071227226681006"
     },
     "user_tz": 420
    },
    "id": "snG19yNIgbEr",
    "outputId": "3d721123-003b-49f8-f7a8-7f1c3817011b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # remember this from yesterday?\n",
    "\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8F0o2wU7hp1x"
   },
   "source": [
    "Next, let's decide what model we are using (let's go with linear regression!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UUDjvVRhhmks"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU6YEMLchtj1"
   },
   "source": [
    "Now, let's implement our step forward feature selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1626279252685,
     "user": {
      "displayName": "STEPHANIE SHIN",
      "photoUrl": "",
      "userId": "10583071227226681006"
     },
     "user_tz": 420
    },
    "id": "ijHrv66XgfXH",
    "outputId": "1a37aefc-5149-4984-e14c-a2d9ab3abb3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(estimator=LinearRegression())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "selector = SequentialFeatureSelector(\n",
    "    lr,\n",
    "    # n_features_to_select='auto',\n",
    "#     direction='forward',\n",
    "#     scoring='r2',\n",
    "#     cv = 5\n",
    ")\n",
    "\n",
    "selector.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5TAbr8MivEb"
   },
   "source": [
    "Now, let's print out which columns (features) were chosen as the optimal featuers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1626279255693,
     "user": {
      "displayName": "STEPHANIE SHIN",
      "photoUrl": "",
      "userId": "10583071227226681006"
     },
     "user_tz": 420
    },
    "id": "AwaT1ADBkCco",
    "outputId": "a31d25ce-5a6d-4689-a5f9-b89c21aca27b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMqMCyP6kJz3"
   },
   "source": [
    "This means it chose 1,3 as our optimal features! `n_features_to_select=None` means it chooses half the features by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Grnn7F3zuJGJ"
   },
   "source": [
    "**Do those results make sense to you?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNqhWCcbkTyH"
   },
   "source": [
    "You can also do `selector.transform(X)` to directly get a transformed version without the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1626279257181,
     "user": {
      "displayName": "STEPHANIE SHIN",
      "photoUrl": "",
      "userId": "10583071227226681006"
     },
     "user_tz": 420
    },
    "id": "l_EI9JTqkc3O",
    "outputId": "d5ec5509-8dd3-4596-80e5-a574f21c9d8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.transform(X_train).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation, Test\n",
    "\n",
    "In a standard machine learning task:\n",
    "- We split the dataset into train, validation, and test, where:\n",
    "  - Training dataset is used to __train__ the model, that is, optimize the model parameters (such as $\\beta$ in Linear Regression model).\n",
    "  - Validation dataset is used to perform __model selection__, i.e., pick the hyperparameters (such as $\\lambda$ in a Lasso or Ridge Regression model).\n",
    "  - Test dataset is used to perform __model evaluation__, which should be the result to report and a mirror of model's true performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases (such as when the model is simple enough and without any hyperparameters) we can also just do a train-test split. In this case: __one doesn't touch the test dataset until the final evaluation!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common trick is to use the `sklearn.train_test_split` function twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 20)\n",
      "(800,)\n",
      "(200, 20)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.random.randn(1000, 20)\n",
    "Y = np.random.randn(1000)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 20)\n",
      "(200, 20)\n",
      "(100, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.random.randn(1000, 20)\n",
    "Y = np.random.randn(1000)\n",
    "\n",
    "# what Can I do if I want to split into 7:2:1?\n",
    "X_train_and_val, X_test, Y_train_and_val, Y_test = train_test_split(X,Y, test_size=0.1)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_and_val, Y_train_and_val, test_size=2/9)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TLHUGdauX-L"
   },
   "source": [
    "# Cross Validation\n",
    "\n",
    "We want to prevent overfitting! So we can cross validate our models onto various data sets and average our performance. There are various methods explained more in lecture\n",
    "\n",
    "*   K-fold\n",
    "*   Leave-One-Out\n",
    "\n",
    "Let's take a look at a dummy example...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show three different ways to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1626279260100,
     "user": {
      "displayName": "STEPHANIE SHIN",
      "photoUrl": "",
      "userId": "10583071227226681006"
     },
     "user_tz": 420
    },
    "id": "8g3ROe22GR_u",
    "outputId": "fb82fcdc-4bbd-4836-93d9-6d404fd2ab3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71751226  0.07990351]\n",
      " [-0.32354951  0.78929814]\n",
      " [ 0.66311697  0.49846643]\n",
      " [ 1.35059174 -1.71411862]\n",
      " [-1.11691643 -1.12927171]\n",
      " [ 0.6897902   0.44821461]\n",
      " [ 0.16038214 -1.16062144]\n",
      " [ 1.18361594 -0.02903249]\n",
      " [ 0.43686078 -0.39934185]\n",
      " [ 0.51059285 -0.74870723]]\n",
      "[[ 0.1463936 ]\n",
      " [-1.10139765]\n",
      " [ 0.08066114]\n",
      " [-0.12159536]\n",
      " [-0.53065554]\n",
      " [ 0.01220013]\n",
      " [-2.33123525]\n",
      " [-0.80534093]\n",
      " [-2.00930942]\n",
      " [ 0.91650753]]\n",
      "TRAIN: [5 6 7 8 9] TEST: [0 1 2 3 4]\n",
      "TRAIN: [0 1 2 3 4] TEST: [5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "X = np.random.randn(10, 2)\n",
    "y = np.random.randn(10, 1)\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "kf = KFold(n_splits=2)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "     X_train, X_test = X[train_index], X[test_index]\n",
    "     y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estimator', 'fit_time', 'score_time', 'test_score']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "lr = Lasso()\n",
    "cv_results = cross_validate(lr, X, y, cv=5, return_estimator=True)\n",
    "sorted(cv_results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00901103, 0.00133395, 0.00101209, 0.00099993, 0.0010252 ]),\n",
       " 'score_time': array([0.        , 0.00099921, 0.00100636, 0.        , 0.        ]),\n",
       " 'estimator': [Lasso(), Lasso(), Lasso(), Lasso(), Lasso()],\n",
       " 'test_score': array([-3.76721979e-02, -4.68763248e+01, -2.10641728e+00, -2.65171000e+00,\n",
       "        -5.71431324e-04])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.76721979e-02, -4.68763248e+01, -2.10641728e+00, -2.65171000e+00,\n",
       "       -5.71431324e-04])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.33453913476973"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lasso(), Lasso(), Lasso(), Lasso(), Lasso()]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.33453913476973\n"
     ]
    }
   ],
   "source": [
    "# easiest one\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(cross_val_score(lr, X,y, cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: why do we want to use cross validation__? \n",
    "\n",
    "- prevent overfitting by model selection \n",
    "- more stable, less variance, more thorough indication of model performance on validation dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: When may we avoid using cross validation?__\n",
    "- when the model is too expensive to train.\n",
    "- when the data is too big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_z141sUcvcX8"
   },
   "source": [
    "# Regularization\n",
    "\n",
    "We don't want to deal with extremes/outliers that may skew our data. Regularization helps us modify our loss function (how much our predictions differed from the actual values). We can use two types of regularization methods. This also helps with overfitting!\n",
    "\n",
    "1.   L1 - Lasso Regularization\n",
    "2.   L2 - Ridge Regularization\n",
    "\n",
    "Let's use MSE (Mean Squared Error) as our loss function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbJ8qG2c9TUd"
   },
   "source": [
    "## Lasso Regularization (L1)\n",
    "\n",
    "AKA Least Absolute Shrinkage and Selection Operator\n",
    "\n",
    "We want to reduce overfitting and control our regularization parameter lambda. Lasso regularization takes the magnitude of our lambda into account by adding a penalty to our loss function which is the absolute value of the magnitude of the coefficient. This method basically shrinks our data until it reaches some middle point. Beware it can lead to a sparse model (small number of coefficients)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xd0mTphh-zUD"
   },
   "source": [
    "Let's look at an example in code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1626380512795,
     "user": {
      "displayName": "Advaith Gowrishetty",
      "photoUrl": "",
      "userId": "06283302651145676231"
     },
     "user_tz": -330
    },
    "id": "43xHhDNB-08D"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1626380515470,
     "user": {
      "displayName": "Advaith Gowrishetty",
      "photoUrl": "",
      "userId": "06283302651145676231"
     },
     "user_tz": -330
    },
    "id": "uJ26zHv6vqgO"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1626380567884,
     "user": {
      "displayName": "Advaith Gowrishetty",
      "photoUrl": "",
      "userId": "06283302651145676231"
     },
     "user_tz": -330
    },
    "id": "RpWFYfjB-6xg",
    "outputId": "073dbef6-41a5-41f6-fbd5-4c63fdfd46e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995061728395062"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = Lasso(alpha=0.1)\n",
    "l1.fit(X_train, y_train)\n",
    "l1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1626380568265,
     "user": {
      "displayName": "Advaith Gowrishetty",
      "photoUrl": "",
      "userId": "06283302651145676231"
     },
     "user_tz": -330
    },
    "id": "eAtItjW2AU-1",
    "outputId": "6d0a4462-f5b1-4aa7-bdbe-5312495b1e60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48888889 0.        ]\n",
      "0.5444444444444443\n"
     ]
    }
   ],
   "source": [
    "print(l1.coef_) # prints the parameters/coefficients for each of our features that will reduce our loss function\n",
    "print(l1.intercept_) # intercept for our loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIpNfrUOB0aZ"
   },
   "source": [
    "Note: Lasso regularization tends to make coefficients zero which ends up reducing features. So it can help us with model/feature selection like we just explored!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ca3qHyaBVal"
   },
   "source": [
    "# Ridge Regularization (L2)\n",
    "\n",
    "Similar to lasso except lasso tends to make its coefficients zero whereas ridge will never do that. In ridge, our penalty is the square of our coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HipCoS99CGwT"
   },
   "source": [
    "Let's look at an example in code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1626380690329,
     "user": {
      "displayName": "Advaith Gowrishetty",
      "photoUrl": "",
      "userId": "06283302651145676231"
     },
     "user_tz": -330
    },
    "id": "iKpc0wokCHNo"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1626380732919,
     "user": {
      "displayName": "Advaith Gowrishetty",
      "photoUrl": "",
      "userId": "06283302651145676231"
     },
     "user_tz": -330
    },
    "id": "sitGRG4bCIyN",
    "outputId": "84c83e82-f600-48a0-c4c8-a4ac6bd0daec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989886972040452"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = Ridge(alpha=0.1)\n",
    "l2.fit(X_train, y_train)\n",
    "l2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1626380735295,
     "user": {
      "displayName": "Advaith Gowrishetty",
      "photoUrl": "",
      "userId": "06283302651145676231"
     },
     "user_tz": -330
    },
    "id": "gwDjQQdUCPWk",
    "outputId": "418d0ea8-9359-41fc-cf0a-77fed0332d42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24390244 0.24390244]\n",
      "0.28048780487804814\n"
     ]
    }
   ],
   "source": [
    "print(l2.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Complete Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we demonstrate a standard way to do model selection and evaluation\n",
    "- Step 1: Split the dataset into train-val and test \n",
    "- Step 2: Define the base estimator (in this case, Lasso)\n",
    "- Step 3: Train and preform model selection ($\\lambda) using cross-validation \n",
    "- Step 4: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(1000, 20)\n",
    "beta = np.random.randn(20)\n",
    "Y = X @ beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1 \n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X,Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.01, 0.1, 1.0, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.01, val_score = 0.9999393095696005\n",
      "alpha = 0.1, val_score = 0.994648878736583\n",
      "alpha = 1.0, val_score = 0.6987415636801432\n",
      "alpha = 10, val_score = -0.0016915166883781473\n",
      "alpha = 20, val_score = -0.0016915166883781473\n"
     ]
    }
   ],
   "source": [
    "for alpha in alphas:\n",
    "    lr = Lasso(alpha=alpha)\n",
    "    val_score = cross_val_score(lr, X_train_val, Y_train_val, cv=5).mean()\n",
    "    print(f\"alpha = {alpha}, val_score = {val_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.01, val_score = 0.9999393095696005\n",
      "alpha = 0.1, val_score = 0.994648878736583\n",
      "alpha = 1.0, val_score = 0.6987415636801432\n",
      "alpha = 10, val_score = -0.0016915166883781473\n",
      "alpha = 20, val_score = -0.0016915166883781473\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "best_model_config = None \n",
    "best_score = -np.inf \n",
    "\n",
    "for alpha in alphas:\n",
    "    lr = Lasso(alpha=alpha)\n",
    "    val_score = cross_val_score(lr, X_train_val, Y_train_val, cv=5).mean()\n",
    "    print(f\"alpha = {alpha}, val_score = {val_score}\")\n",
    "    if val_score >= best_score:\n",
    "        # print(\"better\")\n",
    "        best_model_config = alpha\n",
    "        best_score = val_score\n",
    "\n",
    "        \n",
    "print(best_model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.82826013948301\n"
     ]
    }
   ],
   "source": [
    "lr = Lasso(alpha=best_model_config)\n",
    "lr.fit(X_train_and_val, Y_train_and_val)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(mean_squared_error(y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "OHeN3ilmZapM"
   ],
   "name": "Day 3 (7/14) Regularization and Model Selection",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
